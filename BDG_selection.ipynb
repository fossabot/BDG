{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BDG selection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6O2zjre1dfw"
      },
      "source": [
        "!pip install nlp2go transformers git+https://github.com/Maluuba/nlg-eval.git@master"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HziQzJRO3-Vo"
      },
      "source": [
        "from nlgeval import NLGEval\n",
        "\n",
        "nlgeval = NLGEval(\n",
        "    metrics_to_omit=['METEOR', 'EmbeddingAverageCosineSimilairty', 'SkipThoughtCS', 'VectorExtremaCosineSimilarity',\n",
        "                     'GreedyMatchingScore', 'CIDEr'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uE47nPjfz48Z"
      },
      "source": [
        "!wget https://github.com/voidful/BDG/releases/download/v2.0/BDG.pt\n",
        "!wget https://github.com/voidful/BDG/releases/download/v2.0/BDG_ANPM.pt\n",
        "!wget https://github.com/voidful/BDG/releases/download/v2.0/BDG_PM.pt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35Uj2gLdzh5G"
      },
      "source": [
        "from transformers import RobertaTokenizer\n",
        "from transformers import RobertaForMultipleChoice\n",
        "import torch\n",
        "from torch.distributions import Categorical\n",
        "import itertools as it\n",
        "import nlp2go\n",
        "\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"LIAMF-USP/roberta-large-finetuned-race\")\n",
        "model = RobertaForMultipleChoice.from_pretrained(\"LIAMF-USP/roberta-large-finetuned-race\")\n",
        "model.eval()\n",
        "model.to(\"cuda\")\n",
        "\n",
        "dg_model = nlp2go.Model('./BDG.pt')\n",
        "dg_model_pm = nlp2go.Model('./BDG_PM.pt')\n",
        "dg_model_both = nlp2go.Model('./BDG_ANPM.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmeFM_Z4zvi6"
      },
      "source": [
        "context = \"\"\"There are many things we need to know that we do not learn at school . For example , if we want to use our money wisely , we need to shop carefully . We need to know how to compare the prices of things in different shops . We need to be able to compare the quality of different brands . We need to know how to make a choice when we shop . Knowing how to make such choices is a \" life skill \" , and we need these skills if we are to live useful and happy lives . Some of these choices are small . For example , will I take an apple for lunch or a pear ? Will I go to school by bus or on foot ? Will I wear the red T - shirt or the blue one to the movies ? Other choices are more important . For example , will I eat healthy food for lunch or will eat junk food because it is tastier ? Will I work hard in all my classes or will I only work hard in the classes I enjoy ? We make choices like this every day . We have to realize that the choices we make can affect the rest of our lives . Just as importantly , our choices can also affect other people . The next time you decide to waste time in class , play a joke on someone or talk loudly at the movies , think about this : who else does your choice affect ?\"\"\"\n",
        "question = \"\"\" \"We need \" life skills \"\"\"\n",
        "answer = \"to live useful and happy lives\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bnQ0pQIz0DU"
      },
      "source": [
        "d_input = context + '</s>' + question + '</s>' + answer\n",
        "choices = dg_model.predict(d_input, decodenum=3)['result']\n",
        "choices_pm = dg_model_pm.predict(d_input, decodenum=3)['result']\n",
        "choices_both = dg_model_both.predict(d_input, decodenum=3)['result']\n",
        "all_options = choices + choices_pm + choices_both"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8r0A1uCjzyvc"
      },
      "source": [
        "def selection(context, question, answer, all_options):\n",
        "    max_combin = [0, []]\n",
        "    for combin in set(it.combinations(all_options, 3)):\n",
        "        options = list(combin) + [answer]\n",
        "        keep = True\n",
        "        for i in set(it.combinations(options, 2)):\n",
        "            a = \"\".join([char if char.isalpha() or char == \" \" else \" \" + char + \" \" for char in i[0]])\n",
        "            b = \"\".join([char if char.isalpha() or char == \" \" else \" \" + char + \" \" for char in i[1]])\n",
        "            metrics_dict = nlgeval.compute_individual_metrics([a], b)\n",
        "            if metrics_dict['Bleu_1'] > 0.5:\n",
        "                keep = False\n",
        "                break\n",
        "        if keep:\n",
        "            prompt = context + tokenizer.sep_token + question\n",
        "            encoding_input = []\n",
        "            for choice in options:\n",
        "                encoding_input.append([prompt, choice])\n",
        "            encoding_input.append([prompt, answer])\n",
        "            labels = torch.tensor(len(options) - 1).unsqueeze(0)\n",
        "            encoding = tokenizer(encoding_input, return_tensors='pt', padding=True, truncation='only_first')\n",
        "            outputs = model(**{k: v.unsqueeze(0).to('cuda') for k, v in encoding.items()},\n",
        "                            labels=labels.to('cuda'))  # batch size is 1\n",
        "            entropy = Categorical(probs=torch.softmax(outputs.logits, -1)).entropy().tolist()[0]\n",
        "            if entropy >= max_combin[0]:\n",
        "                max_combin = [entropy, options]\n",
        "    return max_combin[1][:-1]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3X7Gocrlz3Ge"
      },
      "source": [
        "selection(context, question, answer, all_options)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}